{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2645fe82-dc7c-4fd5-a467-ced4426119f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2225899267544737\n",
      "R-squared Score: 0.8301370561019205\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Loading the California housing dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "X, y = data.data, data.target\n",
    "\n",
    "#Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Creating an XGBoost regressor\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "#Training the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Making predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error and R-squared score\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12947ae6-b831-4125-84e0-8a6544581d04",
   "metadata": {},
   "source": [
    "In the above example, the calculated MSE is around 0.22, indicating that the XGBoost regressor's predictions are rather accurate.\n",
    "\n",
    "The R2 value of 0.830 shows that the XGBoost regressor explains about 83% of the variation in the target variable, indicating a rather ideal match.\n",
    "\n",
    "Let's further improve the performance of the XGBoost model with parameter tuning. For example, defining max_depth and n_estimators parameters in our case led to improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310043a4-7fe0-4077-9bac-4dba017cb8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.20484014861251143\n",
      "R-squared Score: 0.8436822762863774\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Creating an XGBoost regressor\n",
    "model = xgb.XGBRegressor(max_depth=4, n_estimators=500)\n",
    "\n",
    "#Training the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Making predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error and R-squared score\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007de97-6d76-4c5e-806f-76d95fd42319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
