{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "sex          0\n",
       "cp          10\n",
       "trestbps     0\n",
       "chol         0\n",
       "fbs          0\n",
       "restecg      0\n",
       "thalach      0\n",
       "exang        0\n",
       "oldpeak      0\n",
       "slope        0\n",
       "ca           0\n",
       "thal         0\n",
       "target       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As the coulmn cp (chest pain) has missing values, we need to impute the data. \n",
    "\n",
    "###### The data is numeric and hence mean stratergy will be a suitable choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Create the imputer object with the desired strategy\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Fit and transform the data\n",
    "df_imputed = imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={0: 'age', 1:'sex', 2:'cp', 3:'trestbps',4: 'chol',5: 'fbs',6: 'restecg',7: 'thalach',8: 'exang',9: 'oldpeak',10: 'slope',11: 'ca',12: 'thal',13:'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to find the most important features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cp          0.138583\n",
       "thalach     0.122994\n",
       "ca          0.107847\n",
       "thal        0.106682\n",
       "oldpeak     0.106565\n",
       "age         0.092637\n",
       "chol        0.078386\n",
       "trestbps    0.072970\n",
       "exang       0.057930\n",
       "slope       0.055453\n",
       "sex         0.031262\n",
       "restecg     0.020414\n",
       "fbs         0.008276\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "model.fit(x,y)\n",
    "pd.Series(model.feature_importances_,index=x.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'cp' column, it records chest pain type. Number 3 mean no chest pain, number 0-2 means different tyoe of angina. \n",
    "\n",
    "# To simplify it, I will group the number0-2 together as disease positive, number 3 as disease negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hi\\AppData\\Local\\Temp\\ipykernel_6072\\3165275533.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['cp'].replace(to_replace=col.cp, value=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "number=[0,1,2]\n",
    "for col in df.itertuples():\n",
    "    if col.cp in number:\n",
    "        df['cp'].replace(to_replace=col.cp, value=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the accuracy when the top 8 features are used for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top8 = df.loc[:,['cp','oldpeak','thal','ca','thalach','age','chol','trestbps','exang']]\n",
    "x_train,x_test,y_train,y_test = train_test_split(df_top8,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7631578947368421\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[27 10]\n",
      " [ 8 31]]\n",
      "\n",
      "\n",
      "Precision:  [0.77142857 0.75609756]\n",
      "Recall:     [0.72972973 0.79487179]\n",
      "Fscore:     [0.75  0.775]\n",
      "Support:    [37 39]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(x_train,y_train)\n",
    "prediction = clf.predict(x_test)\n",
    "accuracy = accuracy_score(prediction,y_test)\n",
    "cm = confusion_matrix(prediction,y_test)\n",
    "prfs = precision_recall_fscore_support(prediction,y_test)\n",
    "print('Accuracy: ',accuracy)\n",
    "print('\\n')\n",
    "print('Confusion Matrix: \\n',cm)\n",
    "print('\\n')\n",
    "print('Precision: ', prfs[0])\n",
    "print('Recall:    ', prfs[1])\n",
    "print('Fscore:    ', prfs[2])\n",
    "print('Support:   ', prfs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14 12 0.868421052631579\n",
      "\n",
      "\n",
      "Confusion Matrix:  [[27 10]\n",
      " [ 8 31]]\n",
      "\n",
      "\n",
      "Precision:  [0.77142857 0.75609756]\n",
      "Recall:     [0.72972973 0.79487179]\n",
      "Fscore:     [0.75  0.775]\n",
      "Support:    [37 39]\n"
     ]
    }
   ],
   "source": [
    "# Took 40 secs\n",
    "maxim = 0\n",
    "n_estimators=0\n",
    "max_depth=0\n",
    "max_cm=0\n",
    "max_prfs=0\n",
    "max_features=0\n",
    "for i in range(5,15):\n",
    "    for j in range(5,15):\n",
    "        for k in range(5,13):\n",
    "            x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
    "            clf = RandomForestClassifier(n_estimators=i,max_depth=j,max_features=k)\n",
    "            clf.fit(x_train,y_train)\n",
    "            prediction = clf.predict(x_test)\n",
    "            accuracy = accuracy_score(prediction,y_test)\n",
    "            cm = confusion_matrix(prediction,y_test)\n",
    "            prfs = precision_recall_fscore_support(prediction,y_test)\n",
    "            if accuracy > maxim:\n",
    "                maxim = accuracy\n",
    "                n_estimators = i\n",
    "                max_depth = j\n",
    "                max_features = k\n",
    "                max_cm = cm\n",
    "                max_prfs=prfs\n",
    "                \n",
    "print(str(i)+\" \"+str(j)+\" \"+str(k)+\" \"+str(maxim))\n",
    "print('\\n')\n",
    "print('Confusion Matrix: ',cm)\n",
    "print('\\n')\n",
    "print('Precision: ', prfs[0])\n",
    "print('Recall:    ', prfs[1])\n",
    "print('Fscore:    ', prfs[2])\n",
    "print('Support:   ', prfs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test if standardization can improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "x_std = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14 12 0.8552631578947368\n"
     ]
    }
   ],
   "source": [
    "maxim = 0\n",
    "n_estimators=0\n",
    "max_depth=0\n",
    "max_features=0\n",
    "for i in range(5,15):\n",
    "    for j in range(5,15):\n",
    "        for k in range(5,13):\n",
    "            x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
    "            clf = RandomForestClassifier(n_estimators=i,max_depth=j,max_features=k)\n",
    "            clf.fit(x_train,y_train)\n",
    "            prediction = clf.predict(x_test)\n",
    "            accuracy = accuracy_score(prediction,y_test)\n",
    "            if accuracy > maxim:\n",
    "                maxim = accuracy\n",
    "                n_estimators = i\n",
    "                max_depth = j\n",
    "                max_features = k\n",
    "print(str(i)+\" \"+str(j)+\" \"+str(k)+\" \"+str(maxim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not that much difference with standardiaztion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier helped in achieving accuracy upto 85.5 % which is very good cosidering the size and quality of data"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
